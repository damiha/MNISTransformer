{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformer import Transformer\n",
    "from mnist_classifier import MNISTClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tokens(text, c_to_i):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for c in text:\n",
    "        res.append(c_to_i[c])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_tokens(tokens, i_to_c):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for t in tokens:\n",
    "        res.append(i_to_c[t])\n",
    "        \n",
    "    return \"\".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, tokens, context_size):\n",
    "        \n",
    "        self.context_size = context_size\n",
    "        self.tokens = torch.tensor(tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens) - self.context_size - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.tokens[idx:(idx + self.context_size)]\n",
    "        y = self.tokens[(idx + 1):(idx + self.context_size + 1)]\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_and_dicts(filename, context_size):\n",
    "    \n",
    "    with open(filename, \"r\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    chars = list(sorted(set(text)))\n",
    "    \n",
    "    print(f\"context size = {context_size}\")\n",
    "    print(f\"#symbols = {len(chars)}\")\n",
    "    \n",
    "    c_to_i = {c:i for i, c in enumerate(chars)}\n",
    "    i_to_c = {i:c for i, c in enumerate(chars)}\n",
    "    \n",
    "    tokens = to_tokens(text, c_to_i)\n",
    "    \n",
    "    print(f\"#tokens in text = {len(tokens)}\")\n",
    "    \n",
    "    return TokenDataset(tokens, context_size), c_to_i, i_to_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context size = 152\n",
      "#symbols = 74\n",
      "#tokens in text = 1529999\n"
     ]
    }
   ],
   "source": [
    "context_size = 152\n",
    "token_dataset, c_to_i, i_to_c = get_dataset_and_dicts(\"mnist10k_as_text.txt\", context_size=context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = torch.utils.data.random_split(token_dataset, [0.9, 0.05, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from: https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(transformer, train_loader, val_loader, n_epochs,\n",
    "          optimizer=None,\n",
    "          lr_scheduler=None,\n",
    "          early_stopper=None,\n",
    "          metrics_per_epoch=10\n",
    "         ):\n",
    "    \n",
    "    transformer = transformer.to(device)\n",
    "    \n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.Adam(transformer.parameters(), lr=3e-4)\n",
    "        print(\"Using default optimizer\")\n",
    "        \n",
    "    if early_stopper is None:\n",
    "        early_stopper = EarlyStopper(patience=3, min_delta=1e-2)\n",
    "        print(\"Using default early stopper\")\n",
    "        \n",
    "    if lr_scheduler is None:\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                                  factor=0.3, patience=3, min_lr=1e-5,\n",
    "                                                                  threshold=1e-3\n",
    "                                                                 )\n",
    "        print(\"Using default LR scheduler\")\n",
    "    \n",
    "    # label smoothing deactivated for now\n",
    "    criterion_train = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "    criterion_test = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_losses_over_epochs = []\n",
    "    val_losses_over_epochs = []\n",
    "    \n",
    "    metrics_every = len(train_loader) // metrics_per_epoch\n",
    "    in_between_epochs = []\n",
    "    in_between_metrics = []\n",
    "    \n",
    "    for epoch_idx in range(n_epochs):\n",
    "        \n",
    "        train_losses_this_batch = []\n",
    "        transformer.train()\n",
    "        \n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch_idx + 1}/{n_epochs}\", unit=\"batch\") as tepoch:\n",
    "            for batch_idx, (batch_x, batch_y) in enumerate(tepoch):\n",
    "\n",
    "                # to GPU\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "\n",
    "                logits = transformer(batch_x)\n",
    "\n",
    "                logits = logits.transpose(1, 2)\n",
    "\n",
    "                loss = criterion_train(logits, batch_y)\n",
    "\n",
    "                train_losses_this_batch.append(loss.item())\n",
    "\n",
    "                if batch_idx % metrics_every == 0:\n",
    "                    in_between_loss = np.mean(np.array(train_losses_this_batch))\n",
    "                    in_between_metrics.append(in_between_loss)\n",
    "                    in_between_epochs.append(epoch_idx + (batch_idx / len(train_loader)))\n",
    "\n",
    "                    tepoch.set_postfix(avg_loss=in_between_loss)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        train_loss_this_epoch = np.mean(np.array(train_losses_this_batch))\n",
    "        train_losses_over_epochs.append(train_loss_this_epoch)\n",
    "        \n",
    "        # for early stopping\n",
    "        val_losses_this_batch = []\n",
    "        \n",
    "        transformer.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (batch_x, batch_y) in enumerate(val_loader):\n",
    "\n",
    "                # to GPU\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "\n",
    "                logits = transformer(batch_x)\n",
    "                \n",
    "                logits = logits.transpose(1, 2)\n",
    "\n",
    "                loss = criterion_test(logits, batch_y)\n",
    "\n",
    "                val_losses_this_batch.append(loss.item())\n",
    "        \n",
    "        val_loss_this_epoch = np.mean(np.array(val_losses_this_batch))\n",
    "        val_losses_over_epochs.append(val_loss_this_epoch)\n",
    "        print(f\"{epoch_idx}. avg. train loss = {train_loss_this_epoch}, avg. val loss = {val_loss_this_epoch}\")\n",
    "        \n",
    "        should_stop = early_stopper.early_stop(val_loss_this_epoch)\n",
    "        lr_scheduler.step(val_loss_this_epoch)\n",
    "        \n",
    "        if should_stop:\n",
    "            print(f\"stopping early (val. loss did not decrease for {early_stopper.patience})\")\n",
    "            break\n",
    "        \n",
    "    return train_losses_over_epochs, in_between_epochs, in_between_metrics, val_losses_over_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_symbols = len(c_to_i.keys())\n",
    "\n",
    "transformer = Transformer(n_symbols, context_size, d_model = 256, n_heads = 8, n_layers=8, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default early stopper\n",
      "Using default LR scheduler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|███████| 10757/10757 [40:20<00:00,  4.44batch/s, avg_loss=0.531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. avg. train loss = 0.5303010509294948, avg. val loss = 0.426700659021486\n"
     ]
    }
   ],
   "source": [
    "train_losses, in_between_epochs, in_between_metrics, val_losses =\\\n",
    "train(transformer, train_loader, val_loader, n_epochs=1, optimizer=optimizer, metrics_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = np.arange(len(train_losses)) + 1.0\n",
    "plt.scatter(epoch_list, train_losses, label=\"train\", c=\"blue\")\n",
    "plt.plot(in_between_epochs, in_between_metrics, c=\"blue\")\n",
    "plt.plot(epoch_list, val_losses, label=\"val\", c=\"orange\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(np.arange(len(train_losses) + 1))\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_samples(response, i_to_c):\n",
    "\n",
    "    text_samples = []\n",
    "\n",
    "    for row in response:\n",
    "        text_sample = ''.join([i_to_c[token.item()] for token in row])\n",
    "        text_samples.append(text_sample)\n",
    "    \n",
    "    return text_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_string(string):\n",
    "    \n",
    "    end_pos = string.find(\")\")\n",
    "    chars = list(string)\n",
    "    \n",
    "    if end_pos > -1:\n",
    "        for i in range(end_pos, len(string)):\n",
    "            chars[i] = \":\"\n",
    "    \n",
    "    chunk_size = 6\n",
    "    \n",
    "    width = height = int(math.sqrt(len(chars)))\n",
    "    \n",
    "    bitmap = np.zeros((30, 30))\n",
    "    \n",
    "    chars_per_row = 30 // chunk_size\n",
    "    \n",
    "    for idx, c in enumerate(chars):\n",
    "        \n",
    "        row_idx = (idx // chars_per_row)\n",
    "        col_idx = idx % chars_per_row\n",
    "        \n",
    "        integer_value = max(0, ord(c) - 58)\n",
    "        \n",
    "        bitstring = format(integer_value, '06b')  # Convert to bitstring without leading '0b'\n",
    "        bit_list = [int(bit) for bit in bitstring]\n",
    "        \n",
    "        y_coord = row_idx\n",
    "        x_coord = (chunk_size * col_idx)\n",
    "        \n",
    "        bitmap[y_coord, x_coord:x_coord + chunk_size] = np.array(bit_list)[:chunk_size]\n",
    "    \n",
    "    return bitmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from mnist_classifier.pth\n"
     ]
    }
   ],
   "source": [
    "mnist_classifier = MNISTClassifier()\n",
    "mnist_classifier.load_model(\"mnist_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_and_plot(transformer,\n",
    "                   c_to_i, i_to_c,\n",
    "                   prompt, n_samples,\n",
    "                   beta,\n",
    "                   show_top_k=-1, classifier=None, beta_c=1.0):\n",
    "    \n",
    "    assert (show_top_k == -1 or classifier is not None), \"show_top_k requires ranking by classifier\"\n",
    "    \n",
    "    sampling_start_time = time.time()\n",
    "    \n",
    "    response = transformer.sample(prompt=prompt, n_tokens=150,\n",
    "                                  n_samples=n_samples, c_to_i=c_to_i, beta=beta)\n",
    "    \n",
    "    sampling_end_time = time.time()\n",
    "    print(f\"Sampling time: {sampling_end_time - sampling_start_time:.2f}s\")\n",
    "    \n",
    "    # Convert the response to text samples\n",
    "    texts = get_text_samples(response, i_to_c)\n",
    "    \n",
    "    # Convert texts to numpy arrays\n",
    "    images = np.array([from_string(text) for text in texts])\n",
    "    conversion_end_time = time.time()\n",
    "    \n",
    "    print(f\"Conversion time: {conversion_end_time - sampling_end_time:.2f}s\")\n",
    "    \n",
    "    torch_images = torch.tensor(images).unsqueeze(1).float()\n",
    "    \n",
    "    if show_top_k != -1:\n",
    "        logits = classifier(torch_images) / beta_c\n",
    "        preds = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # 0 to 9\n",
    "        desired_class = int(prompt)\n",
    "        #print(f\"Desired class: {desired_class}\")\n",
    "        \n",
    "        # sort descending!!!\n",
    "        res = torch.argsort(-preds[:, desired_class]).numpy()\n",
    "        \n",
    "        images = images[res][:show_top_k]\n",
    "        \n",
    "    ranking_time_end = time.time()\n",
    "    print(f\"Ranking time: {ranking_time_end - conversion_end_time:.2f}s\")\n",
    "    \n",
    "    # Calculate the number of rows needed to display the images\n",
    "    nrows = (len(images) + 3) // 4  # Ensure there's enough rows, rounding up\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=4, figsize=(20, nrows*5))  # Each image will have space allocated in the grid\n",
    "    \n",
    "    # Flatten the axes array for easy iteration\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    # Loop through the images and plot them\n",
    "    for i, img in enumerate(images):\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')  # Turn off the axis to only show the image\n",
    "    \n",
    "    # Turn off any unused subplots\n",
    "    for i in range(len(images), len(axs)):\n",
    "        axs[i].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    display_time_end = time.time()\n",
    "    print(f\"Display time: {display_time_end - ranking_time_end:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer.save_model(\"mnist_transformer_1e_10k.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer.load_model(\"mnist_transformer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 9\n",
      "Prompt tokens: [11]\n",
      "Sampling time: 3.12s\n",
      "Conversion time: 0.14s\n",
      "Ranking time: 0.00s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display time: 0.33s\n"
     ]
    }
   ],
   "source": [
    "query_and_plot(transformer, c_to_i, i_to_c, prompt=\"9\",\n",
    "               n_samples = 64, beta=0.8,\n",
    "              show_top_k=8, classifier=mnist_classifier, beta_c = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inpainting",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
